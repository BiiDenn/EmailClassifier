{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"D:\\PTITHCM\\Mon hoc\\HK7(2024-2025)\\IoT_And_Application\\Final\\EmailSpamClassifier_Web\\datasets\\spam.csv\", encoding='latin-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop unnecessary columns\n",
    "df.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], inplace=True)\n",
    "# check data after dropping\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>Messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Labels                                           Messages\n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename column for suitable name\n",
    "df = df.rename(columns={'v1':'Labels', 'v2':'Messages'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Labels      0\n",
       "Messages    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing value\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check duplicate rows\n",
    "df.duplicated(subset='Messages').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate rows, keep the first row\n",
    "df.drop_duplicates(subset='Messages', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check duplicate rows again\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set spam = 0, ham = 1\n",
    "df.loc[df['Labels'] == 'spam', 'Labels',] = 0\n",
    "df.loc[df['Labels'] == 'ham', 'Labels',] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate X (features) and Y (labels)\n",
    "X = df['Messages']\n",
    "Y = df['Labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # remove all non-ASCII characters (retain only standard English characters)\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "    # convert to lowercase for convenient calculating\n",
    "    text = text.lower()\n",
    "    # strip leading and trailing whitespace\n",
    "    text = text.strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the preprocessing function to the message column\n",
    "df['Messages'] = df['Messages'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the processed data to a new CSV file\n",
    "df.to_csv(r\"D:\\PTITHCM\\Mon hoc\\HK7(2024-2025)\\IoT_And_Application\\Final\\EmailSpamClassifier_Web\\datasets\\results.csv\", encoding=\"latin-1\", index=False, columns=['Labels', 'Messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction using TF-IDF\n",
    "feature_extraction = TfidfVectorizer(min_df=1, stop_words='english', lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply TF-IDF vectorization to the training and testing data\n",
    "X_train_features = feature_extraction.fit_transform(X_train)\n",
    "X_test_features = feature_extraction.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert target labels to integer format\n",
    "Y_train = Y_train.astype('int')\n",
    "Y_test = Y_test.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the Tokenizer and fit it on the training data\n",
    "tokenizer = Tokenizer(num_words=500)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"D:\\PTITHCM\\Mon hoc\\HK7(2024-2025)\\IoT_And_Application\\Final\\EmailSpamClassifier_Web\\models\\tokenizer.pkl\", 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad sequences to ensure they all have the same length\n",
    "max_len = max([len(x.split()) for x in X_train]) # Find the maximum text length in the training data \n",
    "X_train_padded = pad_sequences(X_train_seq, maxlen=max_len, padding='post')\n",
    "X_test_padded = pad_sequences(X_test_seq, maxlen=max_len, padding='post')\n",
    "\n",
    "with open(r\"D:\\PTITHCM\\Mon hoc\\HK7(2024-2025)\\IoT_And_Application\\Final\\EmailSpamClassifier_Web\\models\\config.json\", 'w') as f:\n",
    "    json.dump({'max_len': max_len}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the CNN model\n",
    "cnnModel = Sequential([\n",
    "    # embedding layer\n",
    "    Embedding(input_dim=800, output_dim=128),\n",
    "    # convolutional layer\n",
    "    Conv1D(128, 3, activation='relu'),\n",
    "    # another convolutional layer\n",
    "    Conv1D(128, 3, activation='relu'),\n",
    "    # pooling layer\n",
    "    GlobalMaxPooling1D(),\n",
    "    # fully connected layer\n",
    "    Dense(64, activation='relu'),\n",
    "    # dropout for regularization\n",
    "    Dropout(0.5),\n",
    "    # additional dense layer\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    # output layer for binary classification\n",
    "    Dense(1, activation='sigmoid') # use for binary prediction\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "cnnModel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ham emails: 4516\n",
      "Number of spam emails: 653\n"
     ]
    }
   ],
   "source": [
    "# count the number of ham and spam emails\n",
    "category_counts = df['Labels'].value_counts()\n",
    "\n",
    "# Print the number of ham and spam emails\n",
    "print(f\"Number of ham emails: {category_counts[1]}\")\n",
    "print(f\"Number of spam emails: {category_counts[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - accuracy: 0.8555 - loss: 0.4770 - val_accuracy: 0.8646 - val_loss: 0.3073\n",
      "Epoch 2/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.8872 - loss: 0.2368 - val_accuracy: 0.9681 - val_loss: 0.1244\n",
      "Epoch 3/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9732 - loss: 0.0762 - val_accuracy: 0.9729 - val_loss: 0.0987\n",
      "Epoch 4/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9866 - loss: 0.0427 - val_accuracy: 0.9778 - val_loss: 0.1305\n",
      "Epoch 5/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9936 - loss: 0.0315 - val_accuracy: 0.9768 - val_loss: 0.1469\n",
      "Epoch 6/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9972 - loss: 0.0164 - val_accuracy: 0.9729 - val_loss: 0.1554\n",
      "Epoch 7/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9976 - loss: 0.0112 - val_accuracy: 0.9749 - val_loss: 0.2119\n",
      "Epoch 8/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9975 - loss: 0.0087 - val_accuracy: 0.9749 - val_loss: 0.2106\n",
      "Epoch 9/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9980 - loss: 0.0068 - val_accuracy: 0.9739 - val_loss: 0.1992\n",
      "Epoch 10/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9976 - loss: 0.0112 - val_accuracy: 0.9758 - val_loss: 0.2208\n",
      "Epoch 11/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9982 - loss: 0.0085 - val_accuracy: 0.9758 - val_loss: 0.2444\n",
      "Epoch 12/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9991 - loss: 0.0038 - val_accuracy: 0.9778 - val_loss: 0.2901\n",
      "Epoch 13/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9987 - loss: 0.0071 - val_accuracy: 0.9681 - val_loss: 0.3145\n",
      "Epoch 14/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9993 - loss: 0.0027 - val_accuracy: 0.9749 - val_loss: 0.3553\n",
      "Epoch 15/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9691 - val_loss: 0.3772\n",
      "Epoch 16/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9998 - loss: 0.0019 - val_accuracy: 0.9681 - val_loss: 0.3891\n",
      "Epoch 17/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9999 - loss: 0.0019 - val_accuracy: 0.9710 - val_loss: 0.4045\n",
      "Epoch 18/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9998 - loss: 0.0015 - val_accuracy: 0.9729 - val_loss: 0.4226\n",
      "Epoch 19/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9996 - loss: 0.0019 - val_accuracy: 0.9729 - val_loss: 0.4506\n",
      "Epoch 20/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9989 - loss: 0.0030 - val_accuracy: 0.9710 - val_loss: 0.4507\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x140b2fd08f0>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the CNN model\n",
    "cnnModel.fit(X_train_padded, Y_train, epochs=20, batch_size=64, validation_data=(X_test_padded, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9694 - loss: 0.4635\n",
      "Loss on test data: 0.4507347643375397\n",
      "Accuracy on test data: 0.9709864854812622\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model on test data\n",
    "loss, accuracy = cnnModel.evaluate(X_test_padded, Y_test, batch_size=64)\n",
    "print(f\"Loss on test data: {loss}\")\n",
    "print(f\"Accuracy on test data: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        spam       0.89      0.89      0.89       140\n",
      "         ham       0.98      0.98      0.98       894\n",
      "\n",
      "    accuracy                           0.97      1034\n",
      "   macro avg       0.94      0.94      0.94      1034\n",
      "weighted avg       0.97      0.97      0.97      1034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make predictions on the test set\n",
    "y_prediction = (cnnModel.predict(X_test_padded) > 0.5).astype(int)\n",
    "# details report\n",
    "print(classification_report(Y_test, y_prediction, target_names=['spam', 'ham']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save successfully\n"
     ]
    }
   ],
   "source": [
    "# save the trained model\n",
    "cnnModel.save(r\"D:\\PTITHCM\\Mon hoc\\HK7(2024-2025)\\IoT_And_Application\\Final\\EmailSpamClassifier_Web\\models\\cnn_spam_classifier.keras\")\n",
    "print(\"Save successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the saved model\n",
    "loadedCnnModel = load_model(r\"D:\\PTITHCM\\Mon hoc\\HK7(2024-2025)\\IoT_And_Application\\Final\\EmailSpamClassifier_Web\\models\\cnn_spam_classifier.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model with new messages\n",
    "new_message =[\"Congratulations! You've won a $1000 gift card. Claim it now by clicking this link.\", \n",
    "              \"Hello, Mr Linh, you have received a wonderful chance up to 1 billion dollar by clicking on this link.\", \n",
    "              \"Please confirm your attendance to the meeting.\", \n",
    "              \"Win a $1000 award now!\", \n",
    "              \"Hey James, remember to come to the party tomorrow!\",\n",
    "              \"If you want to receive a gift up to $10000, click on this link www.reward.org/gift\", \n",
    "              \"Please confirm your attendance for tomorrow's meeting\"]\n",
    "new_message_seq = tokenizer.texts_to_sequences(new_message)\n",
    "new_message_padded = pad_sequences(new_message_seq, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
      "Predict by CNN:  [[0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "# make predictions on the new messages\n",
    "cnnPrediction = loadedCnnModel.predict(new_message_padded)\n",
    "print(\"Predict by CNN: \", (cnnPrediction > 0.5).astype('int'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
